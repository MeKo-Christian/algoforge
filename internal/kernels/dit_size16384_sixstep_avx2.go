//go:build amd64 && asm && !purego

package kernels

import (
	"github.com/MeKo-Christian/algo-fft/internal/asm/amd64"
	mathpkg "github.com/MeKo-Christian/algo-fft/internal/math"
)

// Precomputed bit-reversal indices for size 128 (radix-2).
// This avoids allocation on every call.
// Generated by ComputeBitReversalIndices(128).
var bitrev128 = [128]int{
	0, 64, 32, 96, 16, 80, 48, 112, 8, 72, 40, 104, 24, 88, 56, 120,
	4, 68, 36, 100, 20, 84, 52, 116, 12, 76, 44, 108, 28, 92, 60, 124,
	2, 66, 34, 98, 18, 82, 50, 114, 10, 74, 42, 106, 26, 90, 58, 122,
	6, 70, 38, 102, 22, 86, 54, 118, 14, 78, 46, 110, 30, 94, 62, 126,
	1, 65, 33, 97, 17, 81, 49, 113, 9, 73, 41, 105, 25, 89, 57, 121,
	5, 69, 37, 101, 21, 85, 53, 117, 13, 77, 45, 109, 29, 93, 61, 125,
	3, 67, 35, 99, 19, 83, 51, 115, 11, 75, 43, 107, 27, 91, 59, 123,
	7, 71, 39, 103, 23, 87, 55, 119, 15, 79, 47, 111, 31, 95, 63, 127,
}

var bitrev16384 = mathpkg.ComputeBitReversalIndices(16384)

// forwardDIT16384SixStepAVX2Complex64 computes a 16384-point forward FFT using the
// six-step (128×128 matrix) algorithm with AVX2-accelerated operations.
//
// This implementation uses:
// - AVX2 assembly for transpose operations (Steps 1, 6)
// - AVX2 assembly for fused transpose+twiddle (Steps 3+4)
// - Existing ForwardAVX2Size128Complex64Asm kernel for row FFTs (Steps 2, 5)
func forwardDIT16384SixStepAVX2Complex64(dst, src, twiddle, scratch []complex64, bitrev []int) bool {
	const (
		n = 16384
		m = 128 // sqrt(16384)
	)

	if len(dst) < n || len(twiddle) < n || len(scratch) < n || len(bitrev) < n || len(src) < n {
		return false
	}

	// Work buffer
	work := scratch[:n]

	// Step 0: Bit-reversal permutation into work (remap dynamic bitrev onto radix-2 order)
	for i := 0; i < n; i++ {
		work[bitrev16384[i]] = src[bitrev[i]]
	}

	// Step 1: Transpose work -> dst (AVX2 accelerated)
	if !amd64.Transpose128x128Complex64AVX2Asm(dst, work) {
		return false
	}

	// Precompute row twiddles for size-128 FFT (stride by 128 to get W_128^k from W_16384^(k*128))
	var rowTwiddle [128]complex64
	for k := 0; k < m; k++ {
		rowTwiddle[k] = twiddle[k*m]
	}

	var rowScratch [128]complex64

	// Step 2: Row FFTs using generic AVX2 DIT (128 FFTs of size 128)
	// Note: We use ForwardAVX2Complex64Asm (generic DIT) instead of ForwardAVX2Size128Complex64Asm
	// (radix-4 variant) because the radix-4 implementation has different output ordering.
	for r := 0; r < m; r++ {
		row := dst[r*m : (r+1)*m]
		if !amd64.ForwardAVX2Complex64Asm(row, row, rowTwiddle[:], rowScratch[:], bitrev128[:]) {
			return false
		}
	}

	// Steps 3+4 fused: Transpose and twiddle multiply (AVX2 accelerated)
	// dst[i*m+j] = work[j*m+i] * W_16384^(i*j)
	if !amd64.TransposeTwiddle128x128Complex64AVX2Asm(work, dst, twiddle) {
		return false
	}

	// Step 5: Row FFTs using generic AVX2 DIT (128 FFTs of size 128)
	for r := 0; r < m; r++ {
		row := work[r*m : (r+1)*m]
		if !amd64.ForwardAVX2Complex64Asm(row, row, rowTwiddle[:], rowScratch[:], bitrev128[:]) {
			return false
		}
	}

	// Step 6: Final transpose work -> dst (AVX2 accelerated)
	if !amd64.Transpose128x128Complex64AVX2Asm(dst, work) {
		return false
	}

	return true
}

// inverseDIT16384SixStepAVX2Complex64 computes a 16384-point inverse FFT using the
// six-step (128×128 matrix) algorithm with AVX2-accelerated operations.
func inverseDIT16384SixStepAVX2Complex64(dst, src, twiddle, scratch []complex64, bitrev []int) bool {
	const (
		n = 16384
		m = 128
	)

	if len(dst) < n || len(twiddle) < n || len(scratch) < n || len(bitrev) < n || len(src) < n {
		return false
	}

	work := scratch[:n]

	// Step 0: Bit-reversal permutation into work (remap dynamic bitrev onto radix-2 order)
	for i := 0; i < n; i++ {
		work[bitrev16384[i]] = src[bitrev[i]]
	}

	// Step 1: Transpose work -> dst (AVX2 accelerated)
	if !amd64.Transpose128x128Complex64AVX2Asm(dst, work) {
		return false
	}

	// Precompute row twiddles
	var rowTwiddle [128]complex64
	for k := 0; k < m; k++ {
		rowTwiddle[k] = twiddle[k*m]
	}

	var rowScratch [128]complex64

	// Step 2: Row IFFTs using generic AVX2 DIT
	for r := 0; r < m; r++ {
		row := dst[r*m : (r+1)*m]
		if !amd64.InverseAVX2Complex64Asm(row, row, rowTwiddle[:], rowScratch[:], bitrev128[:]) {
			return false
		}
	}

	// Steps 3+4 fused: Transpose and conjugate twiddle multiply (AVX2 accelerated)
	// dst[i*m+j] = work[j*m+i] * conj(W_16384^(i*j))
	if !amd64.TransposeTwiddleConj128x128Complex64AVX2Asm(work, dst, twiddle) {
		return false
	}

	// Step 5: Row IFFTs using generic AVX2 DIT
	for r := 0; r < m; r++ {
		row := work[r*m : (r+1)*m]
		if !amd64.InverseAVX2Complex64Asm(row, row, rowTwiddle[:], rowScratch[:], bitrev128[:]) {
			return false
		}
	}

	// Step 6: Final transpose work -> dst (AVX2 accelerated)
	if !amd64.Transpose128x128Complex64AVX2Asm(dst, work) {
		return false
	}

	return true
}
